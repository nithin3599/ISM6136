{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f71b69d6",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45ea72e",
   "metadata": {},
   "source": [
    "\n",
    "## Nithin Reddy Muduganti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f634b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e5d52a",
   "metadata": {},
   "source": [
    "### 2.0 Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f16eb6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"UniversalBank.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dabd3e",
   "metadata": {},
   "source": [
    "### Overview of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94dbfab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
       "0   1   25           1      49     91107       4    1.6          1         0   \n",
       "1   2   45          19      34     90089       3    1.5          1         0   \n",
       "2   3   39          15      11     94720       1    1.0          1         0   \n",
       "\n",
       "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
       "0              0                   1           0       0           0  \n",
       "1              0                   1           0       0           0  \n",
       "2              0                   0           0       0           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891f4c37",
   "metadata": {},
   "source": [
    "### Summary of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70edfbb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                    0\n",
       "Age                   0\n",
       "Experience            0\n",
       "Income                0\n",
       "ZIP Code              0\n",
       "Family                0\n",
       "CCAvg                 0\n",
       "Education             0\n",
       "Mortgage              0\n",
       "Personal Loan         0\n",
       "Securities Account    0\n",
       "CD Account            0\n",
       "Online                0\n",
       "CreditCard            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the missing values by summing the total na's for each variable\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be455ab1",
   "metadata": {},
   "source": [
    "## 3.0 Process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889a0332",
   "metadata": {},
   "source": [
    "We dont have any categorical variables and we dont have any missing values so we need not do any covertion into numeric or we need not impute values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd96e43",
   "metadata": {},
   "source": [
    "### Dropping unessasary columns\n",
    "\n",
    "Dropping unuseful data can help us to process the model quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76f64bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "df = df.drop(columns=['ID', 'ZIP Code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbf77ce",
   "metadata": {},
   "source": [
    "### Splitting the data into train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5037bcd4",
   "metadata": {},
   "source": [
    "Lets split the data into training data and the test data with the ratio of 70-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54713086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into validation and training set\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=1)\n",
    "\n",
    "# to reduce repetition in later code, create variables to represent the columns\n",
    "# that are our predictors and target\n",
    "target = 'CD Account'\n",
    "predictors = list(df.columns)\n",
    "predictors.remove(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eecfa0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a standard scaler and fit it to the training set of predictors\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(train_df[predictors])\n",
    "\n",
    "# Transform the predictors of training and test sets\n",
    "X_train = scaler.transform(train_df[predictors]) \n",
    "y_train = train_df[target] \n",
    "\n",
    "X_test = scaler.transform(test_df[predictors])\n",
    "y_test = test_df[target] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2568de",
   "metadata": {},
   "source": [
    "##  Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7956fbb7",
   "metadata": {},
   "source": [
    "###  Logistic Regression using RandomSearch and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "152b371c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 500 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kanna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "546 fits failed out of a total of 1500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "168 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kanna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Kanna\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Kanna\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "204 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kanna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Kanna\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "174 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kanna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Kanna\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Kanna\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Kanna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.66666667 0.66666667        nan 0.66666667 0.         0.66666667\n",
      " 0.66666667 0.66666667 0.66666667        nan        nan        nan\n",
      "        nan 0.25114155        nan 0.                nan        nan\n",
      " 0.66666667        nan 0.25114155 0.66666667        nan 0.34246575\n",
      " 0.66666667 0.66666667 0.         0.02739726        nan 0.\n",
      "        nan 0.66666667 0.66666667 0.66666667 0.34246575        nan\n",
      " 0.66666667 0.02739726 0.66666667 0.                nan 0.66666667\n",
      "        nan 0.05936073        nan        nan        nan 0.25114155\n",
      "        nan        nan        nan 0.         0.05936073        nan\n",
      "        nan 0.2739726         nan 0.34246575        nan        nan\n",
      " 0.02739726 0.66666667        nan        nan 0.66666667 0.66666667\n",
      " 0.66666667 0.66666667 0.66666667 0.2739726  0.66666667 0.\n",
      "        nan        nan 0.66666667 0.66666667 0.02739726 0.\n",
      "        nan 0.66666667 0.25114155        nan 0.66666667        nan\n",
      "        nan        nan 0.34246575 0.66666667 0.66666667 0.66666667\n",
      " 0.66666667 0.         0.66666667        nan        nan        nan\n",
      "        nan        nan 0.66666667 0.66666667        nan 0.66666667\n",
      "        nan 0.66666667 0.66666667 0.66666667 0.66666667 0.\n",
      " 0.66666667        nan        nan 0.66666667        nan        nan\n",
      "        nan 0.05936073 0.66666667 0.34246575 0.05936073        nan\n",
      "        nan        nan 0.66666667 0.66666667        nan        nan\n",
      " 0.66666667 0.66666667        nan 0.66666667 0.         0.02739726\n",
      " 0.25114155 0.66666667        nan 0.66666667        nan        nan\n",
      " 0.66666667        nan        nan 0.66666667 0.66666667 0.66666667\n",
      " 0.                nan        nan 0.66666667        nan 0.66666667\n",
      " 0.66666667 0.66666667 0.66666667        nan 0.66666667 0.66666667\n",
      " 0.         0.66666667 0.66666667        nan 0.66666667 0.66666667\n",
      "        nan        nan 0.02739726        nan 0.66666667 0.66666667\n",
      " 0.66666667 0.66666667 0.2739726         nan        nan 0.66666667\n",
      " 0.66666667        nan        nan        nan 0.66666667 0.66666667\n",
      "        nan 0.         0.66666667 0.66666667 0.         0.66666667\n",
      "        nan 0.66666667        nan        nan 0.                nan\n",
      "        nan 0.66666667 0.66666667 0.66666667 0.                nan\n",
      " 0.66666667 0.66666667 0.66666667 0.         0.66666667 0.05936073\n",
      " 0.                nan        nan 0.66666667        nan        nan\n",
      " 0.02739726 0.66666667 0.66666667 0.66666667        nan        nan\n",
      " 0.66666667 0.66666667        nan 0.66666667 0.66666667 0.66666667\n",
      " 0.66666667 0.66666667 0.66666667 0.66666667        nan 0.\n",
      "        nan 0.66666667 0.66666667        nan 0.         0.66666667\n",
      " 0.66666667        nan 0.2739726  0.05936073 0.05936073 0.\n",
      "        nan 0.66666667 0.66666667        nan 0.66666667        nan\n",
      " 0.66666667        nan 0.25114155 0.66666667 0.02739726 0.66666667\n",
      " 0.66666667 0.                nan 0.66666667 0.66666667 0.66666667\n",
      "        nan 0.         0.66666667 0.66666667 0.25114155        nan\n",
      " 0.         0.02739726 0.66666667        nan 0.66666667 0.34246575\n",
      " 0.66666667        nan 0.34246575 0.66666667 0.66666667 0.66666667\n",
      " 0.66666667        nan 0.66666667 0.66666667 0.66666667 0.66666667\n",
      " 0.66666667        nan        nan        nan        nan 0.66666667\n",
      " 0.                nan 0.66666667        nan 0.         0.\n",
      " 0.66666667 0.66666667 0.66666667 0.66666667 0.25114155        nan\n",
      " 0.                nan 0.2739726         nan 0.66666667        nan\n",
      " 0.66666667        nan        nan        nan 0.66666667        nan\n",
      " 0.66666667 0.66666667        nan 0.                nan        nan\n",
      " 0.66666667 0.66666667        nan 0.02739726 0.66666667 0.66666667\n",
      " 0.25114155 0.         0.66666667        nan 0.66666667 0.2739726\n",
      " 0.66666667        nan        nan 0.66666667 0.66666667 0.66666667\n",
      "        nan 0.66666667 0.34246575 0.66666667 0.66666667 0.\n",
      " 0.34246575        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.05936073 0.66666667 0.66666667 0.66666667\n",
      " 0.         0.66666667        nan 0.25114155 0.66666667        nan\n",
      "        nan 0.66666667 0.66666667 0.34246575 0.66666667        nan\n",
      "        nan        nan 0.         0.66666667 0.66666667 0.25114155\n",
      " 0.66666667 0.66666667        nan 0.                nan 0.66666667\n",
      " 0.66666667 0.66666667        nan        nan 0.66666667        nan\n",
      " 0.         0.66666667        nan 0.66666667 0.66666667 0.66666667\n",
      " 0.05936073        nan 0.25114155 0.02739726 0.05936073        nan\n",
      " 0.02739726 0.66666667        nan        nan 0.66666667 0.66666667\n",
      " 0.34246575 0.2739726  0.66666667        nan 0.66666667 0.66666667\n",
      " 0.66666667        nan 0.25114155        nan 0.66666667 0.05936073\n",
      " 0.66666667        nan 0.66666667 0.66666667        nan        nan\n",
      " 0.66666667        nan        nan 0.66666667        nan 0.66666667\n",
      " 0.2739726  0.66666667        nan 0.         0.66666667 0.66666667\n",
      " 0.66666667 0.66666667        nan 0.66666667        nan 0.66666667\n",
      " 0.66666667 0.66666667 0.66666667 0.66666667 0.66666667 0.25114155\n",
      " 0.66666667        nan 0.66666667        nan 0.66666667 0.66666667\n",
      " 0.66666667 0.                nan        nan 0.66666667        nan\n",
      " 0.66666667        nan 0.25114155        nan        nan 0.66666667\n",
      " 0.66666667        nan 0.66666667 0.34246575 0.66666667        nan\n",
      " 0.         0.66666667        nan 0.66666667        nan        nan\n",
      " 0.                nan 0.66666667 0.66666667 0.66666667 0.\n",
      "        nan        nan        nan 0.66666667        nan        nan\n",
      "        nan 0.34246575        nan        nan        nan 0.05936073\n",
      "        nan        nan 0.66666667 0.25114155        nan 0.66666667\n",
      " 0.66666667 0.66666667]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 3\n",
    "\n",
    "param_grid = {'C':[0.001,0.01,0.1,1,5],\n",
    "               'penalty':['l1', 'l2','elasticnet','none'],\n",
    "              'solver':['saga','liblinear'],\n",
    "              'max_iter': np.arange(500,1000)\n",
    "                  \n",
    "}\n",
    "\n",
    "logistic_regression = LogisticRegression()\n",
    "rand_search = RandomizedSearchCV(estimator =logistic_regression, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1  \n",
    "                                )\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "bestlogestic = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92ba3b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 400 candidates, totalling 1200 fits\n",
      "The best recall score is 0.6666666666666666\n",
      "... with parameters: {'C': 0.05, 'max_iter': 732, 'penalty': 'l1', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 3\n",
    "best_penality = rand_search.best_params_['penalty']\n",
    "best_solver = rand_search.best_params_['solver']\n",
    "min_regulization_strength=rand_search.best_params_['C']\n",
    "min_iter = rand_search.best_params_['max_iter']\n",
    "\n",
    "param_grid = {\n",
    "    \n",
    "    'C':np.arange(min_regulization_strength-0.05,min_regulization_strength+0.05), \n",
    "               'penalty':[best_penality],\n",
    "              'solver':[best_solver],\n",
    "              'max_iter': np.arange(min_iter-200,min_iter+200)\n",
    "}\n",
    "\n",
    "logistic_gridsearch =  LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator = logistic_gridsearch, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1 # n_jobs=-1 will utilize all available CPUs \n",
    "                )\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestlgr = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71747d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.9780000 Precision=1.0000000 Recall=0.6024096 F1=0.7518797\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "Recall_lr={TP/(TP+FN)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25ea9de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29bbcb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.concat([performance, pd.DataFrame({'model':\"logistic using random & grid search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cbfd0e",
   "metadata": {},
   "source": [
    "###  Modeling the data using individual logestic regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9d565a",
   "metadata": {},
   "source": [
    "####  Fit and test a Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0ffd1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = LogisticRegression(penalty='none', max_iter=900)\n",
    "_ = log_reg_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a78b3952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision   Recall       F1\n",
       "0  logistic using random & grid search     0.978        1.0  0.60241  0.75188\n",
       "0                     default logistic     0.978        1.0  0.60241  0.75188"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = log_reg_model.predict(X_test)\n",
    "c_matrix_1 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_1[1][1]\n",
    "TN = c_matrix_1[0][0]\n",
    "FP = c_matrix_1[0][1]\n",
    "FN = c_matrix_1[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"default logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07585d6c",
   "metadata": {},
   "source": [
    "#### Change to liblinear solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5713f3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_liblin_model = LogisticRegression(solver='liblinear').fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "358bd5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liblinear logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision   Recall       F1\n",
       "0  logistic using random & grid search     0.978        1.0  0.60241  0.75188\n",
       "0                     default logistic     0.978        1.0  0.60241  0.75188\n",
       "0                   liblinear logistic     0.978        1.0  0.60241  0.75188"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = log_reg_liblin_model.predict(X_test)\n",
    "c_matrix_2 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_2[1][1]\n",
    "TN = c_matrix_2[0][0]\n",
    "FP = c_matrix_2[0][1]\n",
    "FN = c_matrix_2[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"liblinear logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79295580",
   "metadata": {},
   "source": [
    "####  L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c348fe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_L2_model = LogisticRegression(penalty='l2', max_iter=1000)\n",
    "_ = log_reg_L2_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ee84c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liblinear logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L2 logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision   Recall       F1\n",
       "0  logistic using random & grid search     0.978        1.0  0.60241  0.75188\n",
       "0                     default logistic     0.978        1.0  0.60241  0.75188\n",
       "0                   liblinear logistic     0.978        1.0  0.60241  0.75188\n",
       "0                          L2 logistic     0.978        1.0  0.60241  0.75188"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds_3 = log_reg_L2_model.predict(X_test)\n",
    "c_matrix_3 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_3[1][1]\n",
    "TN = c_matrix_3[0][0]\n",
    "FP = c_matrix_3[0][1]\n",
    "FN = c_matrix_3[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"L2 logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eeb360",
   "metadata": {},
   "source": [
    "####  L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b581eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_L1_model = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "_ = log_reg_L1_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecc49190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liblinear logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L2 logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1 logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision   Recall       F1\n",
       "0  logistic using random & grid search     0.978        1.0  0.60241  0.75188\n",
       "0                     default logistic     0.978        1.0  0.60241  0.75188\n",
       "0                   liblinear logistic     0.978        1.0  0.60241  0.75188\n",
       "0                          L2 logistic     0.978        1.0  0.60241  0.75188\n",
       "0                          L1 logistic     0.978        1.0  0.60241  0.75188"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = log_reg_L1_model.predict(X_test)\n",
    "c_matrix_4 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_4[1][1]\n",
    "TN = c_matrix_4[0][0]\n",
    "FP = c_matrix_4[0][1]\n",
    "FN = c_matrix_4[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"L1 logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d03a5c1",
   "metadata": {},
   "source": [
    "####  Elastic Net Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71671e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_elastic_model = LogisticRegression(solver='saga', penalty='elasticnet', l1_ratio=0.5, max_iter=1000)\n",
    "_ = log_reg_elastic_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09c6ee2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liblinear logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L2 logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1 logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elestic logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision   Recall       F1\n",
       "0  logistic using random & grid search     0.978        1.0  0.60241  0.75188\n",
       "0                     default logistic     0.978        1.0  0.60241  0.75188\n",
       "0                   liblinear logistic     0.978        1.0  0.60241  0.75188\n",
       "0                          L2 logistic     0.978        1.0  0.60241  0.75188\n",
       "0                          L1 logistic     0.978        1.0  0.60241  0.75188\n",
       "0                     Elestic logistic     0.978        1.0  0.60241  0.75188"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = log_reg_elastic_model.predict(X_test)\n",
    "c_matrix_5 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_5[1][1]\n",
    "TN = c_matrix_5[0][0]\n",
    "FP = c_matrix_5[0][1]\n",
    "FN = c_matrix_5[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Elestic logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8600e0",
   "metadata": {},
   "source": [
    "####  Summary for logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4057a155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liblinear logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L2 logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1 logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elestic logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision   Recall       F1\n",
       "0  logistic using random & grid search     0.978        1.0  0.60241  0.75188\n",
       "0                     default logistic     0.978        1.0  0.60241  0.75188\n",
       "0                   liblinear logistic     0.978        1.0  0.60241  0.75188\n",
       "0                          L2 logistic     0.978        1.0  0.60241  0.75188\n",
       "0                          L1 logistic     0.978        1.0  0.60241  0.75188\n",
       "0                     Elestic logistic     0.978        1.0  0.60241  0.75188"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.sort_values(by=['Recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b822824",
   "metadata": {},
   "source": [
    "###  Model the data using the SVM models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430d65cc",
   "metadata": {},
   "source": [
    "###  SVM using RandomSearch and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "baa70834",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (2821398556.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [24]\u001b[1;36m\u001b[0m\n\u001b[1;33m    )\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 3\n",
    "\n",
    "param_grid = {'C':np.arange(0.1,50,10),  \n",
    "               'kernel':['linear', 'rbf','poly'],\n",
    "              'gamma':['scale','auto'],\n",
    "              'degree':np.arange(1,10), \n",
    "              'coef0':np.arange(1,10) \n",
    "                  \n",
    "}\n",
    "\n",
    "svc = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator =svc, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1  \n",
    "                                )\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    ")\n",
    "\n",
    "bestsvc = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f421eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 3\n",
    "best_kernel = rand_search.best_params_['kernel']\n",
    "best_gamma = rand_search.best_params_['gamma']\n",
    "min_regulization=rand_search.best_params_['C']\n",
    "best_degree = rand_search.best_params_['degree']\n",
    "best_coef0=rand_search.best_params_['coef0']\n",
    "\n",
    "param_grid = {\n",
    "    \n",
    "    'C':np.arange(min_regulization-3,min_regulization+3), \n",
    "               'kernel':[best_kernel],\n",
    "              'gamma':[best_gamma],\n",
    "              'degree': np.arange(best_degree-1,best_degree+1),\n",
    "            'coef0': np.arange(best_coef0-3,best_coef0+3)\n",
    "}\n",
    "\n",
    "svm_grid =  SVC()\n",
    "grid_search = GridSearchCV(estimator = svm_grid, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1 # n_jobs=-1 will utilize all available CPUs \n",
    "                )\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "best_svm = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363b46e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "Recall_svm={TP/(TP+FN)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e953fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_svm = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd9856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_svm = pd.concat([performance_svm, pd.DataFrame({'model':\"svm using Random & Grid search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5001e00c",
   "metadata": {},
   "source": [
    "###  Modeling the Data using indivdual SVM models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40b167a",
   "metadata": {},
   "source": [
    "###  Fit a SVM classification model using linear kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2c42ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_lin_model = SVC(kernel=\"linear\")\n",
    "_ = svm_lin_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a822e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preds = svm_lin_model.predict(X_test)\n",
    "c_matrix_6 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_6[1][1]\n",
    "TN = c_matrix_6[0][0]\n",
    "FP = c_matrix_6[0][1]\n",
    "FN = c_matrix_6[1][0]\n",
    "performance_svm = pd.concat([performance_svm, pd.DataFrame({'model':\"linear svm\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8a45d3",
   "metadata": {},
   "source": [
    "###  Fit a SVM classification model using rbf kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814ad532",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_model = SVC(kernel=\"rbf\", C=10, gamma='scale')\n",
    "_ = svm_rbf_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beead2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preds = svm_rbf_model.predict(X_test)\n",
    "c_matrix_7 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_7[1][1]\n",
    "TN = c_matrix_7[0][0]\n",
    "FP = c_matrix_7[0][1]\n",
    "FN = c_matrix_7[1][0]\n",
    "performance_svm = pd.concat([performance_svm, pd.DataFrame({'model':\"rbf svm\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2859ef55",
   "metadata": {},
   "source": [
    "###  Fit a SVM classification model using polynomial kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18b19bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly_model = SVC(kernel=\"poly\", degree=3, coef0=1, C=10)\n",
    "_ = svm_poly_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eb36bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preds = svm_poly_model.predict(X_test)\n",
    "c_matrix_8 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_8[1][1]\n",
    "TN = c_matrix_8[0][0]\n",
    "FP = c_matrix_8[0][1]\n",
    "FN = c_matrix_8[1][0]\n",
    "performance_svm = pd.concat([performance_svm, pd.DataFrame({'model':\"poly svm\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a4a702",
   "metadata": {},
   "source": [
    "### Summary of the SVM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54d7a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_svm.sort_values(by=['Recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4221c4a",
   "metadata": {},
   "source": [
    "###  Decision Trees using RandomSearchCV combined with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749dfb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 3\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,50),  \n",
    "    'min_samples_leaf': np.arange(1,50),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 50), \n",
    "    'max_depth': np.arange(1,25), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b9d481",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "min_samples_split = rand_search.best_params_['min_samples_split']\n",
    "min_samples_leaf = rand_search.best_params_['min_samples_leaf']\n",
    "min_impurity_decrease = rand_search.best_params_['min_impurity_decrease']\n",
    "max_leaf_nodes = rand_search.best_params_['max_leaf_nodes']\n",
    "max_depth = rand_search.best_params_['max_depth']\n",
    "criterion = rand_search.best_params_['criterion']\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(min_samples_split-2,min_samples_split+2),  \n",
    "    'min_samples_leaf': np.arange(min_samples_leaf-2,min_samples_leaf+2),\n",
    "    'min_impurity_decrease': np.arange(min_impurity_decrease-0.0001, min_impurity_decrease+0.0001, 0.00005),\n",
    "    'max_leaf_nodes': np.arange(max_leaf_nodes-2,max_leaf_nodes+2), \n",
    "    'max_depth': np.arange(max_depth-2,max_depth+2), \n",
    "    'criterion': [criterion]\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06781f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25372b1a",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812f0bec",
   "metadata": {},
   "source": [
    "From the above performed models here by we can conclude that decision tree has the highest recall value when compared to other models so the decision tree model is thr best fit for thr data provided ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aea49a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
